{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Mining Common Crawl URL Data with PySpark \n",
    "This notebook derives heavily from this excellent [Medium blog post](https://towardsdatascience.com/large-scale-graph-mining-with-spark-part-2-2c3d9ed15bb5) by Win Suen on the same topic. Our goal is to extend on the upstream and downstream parts of the actual graph analysis from Win's [original notebook](https://github.com/wsuen/pygotham2018_graphmining/blob/master/notebooks/Graphframes_demo.ipynb), and to document any interesting observations that we make. All our ETL and visualization code is published in this repository.\n",
    "\n",
    "In addition to performing analysis on graphframe objects in PySpark, we aim to visualize the communities detected using tools like D3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages graphframes:graphframes:0.6.0-spark2.3-s_2.11 pyspark-shell'\n",
    "import pyspark\n",
    "from pyspark.sql import * \n",
    "from pyspark.sql.functions import udf, col, desc\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(\"local[*]\")\n",
    "spark = SparkSession.builder.appName('notebook').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "Our PySpark ETL code extracts relevant URLs from the CommonCrawl WARC files and outputs them parquet files. We now read them for community clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.parquet(\"./bootstrap/spark-warehouse/sep_2017\")\n",
    "df = df.distinct().limit(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a subset of the data\n",
    "We visualize just a subset of the data with common children as below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+\n",
      "|              parent|           parentTLD|   childTLD|               child|\n",
      "+--------------------+--------------------+-----------+--------------------+\n",
      "|http://aspireholi...|aspireholidays.co.uk|twitter.com|http://twitter.co...|\n",
      "|http://aftertheco...|   afterthecorps.com|twitter.com|http://twitter.co...|\n",
      "|http://archive.bo...|  archive.boston.com|twitter.com|https://twitter.c...|\n",
      "|http://allabouthe...|   allaboutherbs.org|twitter.com|https://twitter.c...|\n",
      "|http://archive.fo...| archive.fortune.com|twitter.com|https://twitter.c...|\n",
      "|http://animecons.com|       animecons.com|twitter.com|https://twitter.c...|\n",
      "|http://asrar7days...|      asrar7days.com|twitter.com|http://twitter.co...|\n",
      "|http://articles.c...|articles.chicagot...|twitter.com|http://twitter.co...|\n",
      "| http://bitex.com.vn|        bitex.com.vn|twitter.com|  http://twitter.com|\n",
      "|http://archive.co...|archive.constantc...|twitter.com|http://twitter.co...|\n",
      "+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "focus = 'twitter'\n",
    "df = df.where(df.child.contains(focus))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select set of parents and children TLDs (nodes) to assign id for each node.\n",
    "assignID = df.select(\"parentTLD\",\"childTLD\").rdd.flatMap(lambda x: x).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unique hashkeys to each item in the nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashnode(x):\n",
    "    # Assign unique 8-digit hex hashkey to each item\n",
    "    return hashlib.sha1(x.encode(\"UTF-8\")).hexdigest()[:8]\n",
    "\n",
    "hashnode_udf = udf(hashnode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define graph vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|      id|                name|\n",
      "+--------+--------------------+\n",
      "|1ca72648|aspireholidays.co.uk|\n",
      "|465806fb|         twitter.com|\n",
      "|9858ddd3|   afterthecorps.com|\n",
      "|3a2c956e|  archive.boston.com|\n",
      "|e39256d7|   allaboutherbs.org|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertices = assignID.map(lambda x: (hashnode(x), x)).toDF([\"id\",\"name\"])\n",
    "vertices.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define graph edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|     src|     dst|\n",
      "+--------+--------+\n",
      "|1ca72648|465806fb|\n",
      "|9858ddd3|465806fb|\n",
      "|3a2c956e|465806fb|\n",
      "|e39256d7|465806fb|\n",
      "|f9691dc2|465806fb|\n",
      "+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges = df.select(\"parentTLD\",\"childTLD\")\\\n",
    "    .withColumn(\"src\", hashnode_udf(\"parentTLD\"))\\\n",
    "    .withColumn(\"dst\", hashnode_udf(\"childTLD\"))\\\n",
    "    .select(\"src\",\"dst\")\n",
    "edges.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GraphFrame in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Label-Propagation Analysis (LPA)\n",
    "LPA is a community detection algorithm for large-scale graph networks [Original paper](https://arxiv.org/pdf/0709.2938.pdf). The main benefit of using LPA is that it does not require any prior labeling of the dataset prior to community detection - the algorithm iteratively connects groups of nodes based on a consensus of unique labels using the intrinsic information in the graph itself! \n",
    "\n",
    "LPA is implemented in PySpark graphframes and is run as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+\n",
      "|      id|                name|       label|\n",
      "+--------+--------------------+------------+\n",
      "|22f34613| biznes-bulgaria.com|429496729600|\n",
      "|9dd923ac|          7dniv.info|429496729600|\n",
      "|daaaa8f6|archive.constantc...|429496729600|\n",
      "|804ff334|         acidcow.com|429496729600|\n",
      "|6c4680a3|    antigo.chuza.org|429496729600|\n",
      "|f8a6bd9e|  anunciamano.com.ar|429496729600|\n",
      "|d2c250b7|      asrar7days.com|429496729600|\n",
      "|27f1947d|     autos.mlive.com|429496729600|\n",
      "|9858ddd3|   afterthecorps.com|429496729600|\n",
      "|82c418b5|   balidiscovery.com|429496729600|\n",
      "+--------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "communities = graph.labelPropagation(maxIter=5)\n",
    "communities.persist().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-------------------+\n",
      "|      id|          pagerank|               name|\n",
      "+--------+------------------+-------------------+\n",
      "|465806fb|26.200405836312694|        twitter.com|\n",
      "|2d723324|0.6811286114600442|           nola.com|\n",
      "|407eca8a|0.5121267755338679|      animecons.com|\n",
      "|9858ddd3|0.5121267755338679|  afterthecorps.com|\n",
      "|f9691dc2|0.5121267755338679|archive.fortune.com|\n",
      "+--------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = graph.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.select(\"id\", \"pagerank\")\\\n",
    "    .join(vertices, on=\"id\").orderBy(\"pagerank\", ascending=False)\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TriangleCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+\n",
      "|count|      id|                name|\n",
      "+-----+--------+--------------------+\n",
      "|    0|9dd923ac|          7dniv.info|\n",
      "|    0|3eaf8394|      autos.nola.com|\n",
      "|    0|407eca8a|       animecons.com|\n",
      "|    0|f9691dc2| archive.fortune.com|\n",
      "|    0|546cb1d0|autoteile-online.biz|\n",
      "+-----+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trg_count = graph.triangleCount().show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
